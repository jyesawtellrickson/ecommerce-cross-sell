{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 17\n",
    "np.random.seed(seed)\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# rename and remove\n",
    "data = data.rename(index=str, columns={\"activity id\": \"activity_id\"}).drop(['activity_name'], axis=1)\n",
    "\n",
    "# convert to datetime\n",
    "data['date_booking'] = data['date_booking'].apply(lambda x: datetime.strptime(x,'%d/%m/%y'))\n",
    "\n",
    "data_old = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "data = data_old\n",
    "keep_act = sorted(data.activity_id.value_counts().index[:50].tolist())\n",
    "data['keep'] = data['activity_id'].apply(lambda x: x in keep_act)\n",
    "\n",
    "data = data[data['keep']==True]\n",
    "\n",
    "# should split data by country to improve efficiency of model tranining.\n",
    "# a seperate cross-country net can be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>guest_id</th>\n",
       "      <th>activity_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23687.000000</td>\n",
       "      <td>23687.000000</td>\n",
       "      <td>23687.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>98649.553764</td>\n",
       "      <td>121904.469160</td>\n",
       "      <td>5356.660995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18023.692658</td>\n",
       "      <td>23234.439161</td>\n",
       "      <td>3353.577164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>42650.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>405.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>85118.500000</td>\n",
       "      <td>106392.000000</td>\n",
       "      <td>1625.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100061.000000</td>\n",
       "      <td>125118.000000</td>\n",
       "      <td>4654.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113932.500000</td>\n",
       "      <td>141031.500000</td>\n",
       "      <td>8667.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>127257.000000</td>\n",
       "      <td>155513.000000</td>\n",
       "      <td>10369.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_id       guest_id   activity_id\n",
       "count   23687.000000   23687.000000  23687.000000\n",
       "mean    98649.553764  121904.469160   5356.660995\n",
       "std     18023.692658   23234.439161   3353.577164\n",
       "min     42650.000000      29.000000    405.000000\n",
       "25%     85118.500000  106392.000000   1625.000000\n",
       "50%    100061.000000  125118.000000   4654.000000\n",
       "75%    113932.500000  141031.500000   8667.000000\n",
       "max    127257.000000  155513.000000  10369.000000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary of guests with values equal to their ordered ticket purchases\n",
    "test_guests = data.groupby(['guest_id'])['order_id'].count()\n",
    "test_guests = test_guests[test_guests > 1].index.tolist()\n",
    "# build activity lists\n",
    "guest_activities = dict(zip(test_guests, [[] for i in range(0, len(test_guests))]))\n",
    "data_sorted = data.sort_values(['date_booking'], axis=0)\n",
    "data_sorted = data_sorted[['guest_id', 'activity_id']]\n",
    "for index, row in data_sorted.iterrows():\n",
    "    if row['guest_id'] in test_guests:\n",
    "        guest_activities[row['guest_id']] += [row['activity_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "[([7245], 4654), ([7245, 4654], 7092), ([4654], 9392), ([1205], 10277), ([1625], 1625), ([2703], 2703), ([2703, 2703], 2703), ([10277], 10277), ([1205], 10277), ([1757], 10277), ([2703], 2703), ([2703, 2703], 2703), ([1119], 7496), ([6977], 9392), ([6977, 9392], 9461), ([634], 4250), ([6588], 1205), ([7014], 7092), ([2635], 2635), ([10277], 1757)]\n"
     ]
    }
   ],
   "source": [
    "def list_to_cols(l, cols):\n",
    "    return [l.count(i) for i in cols]\n",
    "\n",
    "# build list of test cases which contain a tuple with 1-many activities as list input and one activity as output\n",
    "test_cases = []\n",
    "for key in guest_activities.keys():\n",
    "    for i in range(0, len(guest_activities[key])-1):\n",
    "        test_cases += [(guest_activities[key][:i+1], guest_activities[key][i+1])]\n",
    "\n",
    "cols = sorted(list(data.activity_id.unique()))\n",
    "new = pd.DataFrame(columns=cols)\n",
    "new_out = pd.DataFrame(columns=cols)\n",
    "\n",
    "num = len(test_cases)\n",
    "\n",
    "for i in range(0, num): #len(test_cases)):\n",
    "    # convert list of inputs to columns\n",
    "    t = list_to_cols(test_cases[i][0], cols)\n",
    "    new = new.append(pd.DataFrame([t],columns=cols))\n",
    "    # for predictions, just set all to 0 then update specific cell to 1\n",
    "    t = [0 for i in range(len(cols))]\n",
    "    new_out = new_out.append(pd.DataFrame([t],columns=cols))\n",
    "    new_out.iloc[i][test_cases[i][1]] = 1\n",
    "    if (i % 200 == 0):\n",
    "        print(i/num)\n",
    "\n",
    "print(test_cases[:20])\n",
    "\n",
    "X = new.values\n",
    "Y = new_out.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1688, 50)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into training and testing 67/33\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.33, random_state=seed)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=50, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(50, activation='softmax')) # sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1688/1688 [==============================] - 0s - loss: 3.3365 - top_k_categorical_accuracy: 0.4751     \n",
      "Epoch 2/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.7914 - top_k_categorical_accuracy: 0.5895     \n",
      "Epoch 3/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.5601 - top_k_categorical_accuracy: 0.6404     \n",
      "Epoch 4/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.4104 - top_k_categorical_accuracy: 0.7032     \n",
      "Epoch 5/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.3156 - top_k_categorical_accuracy: 0.7322     \n",
      "Epoch 6/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.2487 - top_k_categorical_accuracy: 0.7470     \n",
      "Epoch 7/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.1998 - top_k_categorical_accuracy: 0.7541     \n",
      "Epoch 8/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.1598 - top_k_categorical_accuracy: 0.7648      ETA: 0s - loss: 2.1158 - top_k_categorical_accu\n",
      "Epoch 9/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.1325 - top_k_categorical_accuracy: 0.7630     \n",
      "Epoch 10/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.1079 - top_k_categorical_accuracy: 0.7743     \n",
      "Epoch 11/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.0919 - top_k_categorical_accuracy: 0.7761     \n",
      "Epoch 12/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.0771 - top_k_categorical_accuracy: 0.7784     \n",
      "Epoch 13/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.0657 - top_k_categorical_accuracy: 0.7838     \n",
      "Epoch 14/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.0560 - top_k_categorical_accuracy: 0.7832     \n",
      "Epoch 15/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.0474 - top_k_categorical_accuracy: 0.7844     \n",
      "Epoch 16/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.0379 - top_k_categorical_accuracy: 0.7897     \n",
      "Epoch 17/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.0291 - top_k_categorical_accuracy: 0.7897     \n",
      "Epoch 18/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.0215 - top_k_categorical_accuracy: 0.7885     \n",
      "Epoch 19/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.0113 - top_k_categorical_accuracy: 0.8004     \n",
      "Epoch 20/150\n",
      "1688/1688 [==============================] - 0s - loss: 2.0092 - top_k_categorical_accuracy: 0.7927     \n",
      "Epoch 21/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9988 - top_k_categorical_accuracy: 0.7986     \n",
      "Epoch 22/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9950 - top_k_categorical_accuracy: 0.8009     \n",
      "Epoch 23/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9910 - top_k_categorical_accuracy: 0.8033     \n",
      "Epoch 24/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9841 - top_k_categorical_accuracy: 0.8033     \n",
      "Epoch 25/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9748 - top_k_categorical_accuracy: 0.8039     \n",
      "Epoch 26/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9688 - top_k_categorical_accuracy: 0.8033     \n",
      "Epoch 27/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9647 - top_k_categorical_accuracy: 0.8098     \n",
      "Epoch 28/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9615 - top_k_categorical_accuracy: 0.8075     \n",
      "Epoch 29/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9560 - top_k_categorical_accuracy: 0.8045     \n",
      "Epoch 30/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9488 - top_k_categorical_accuracy: 0.8128     \n",
      "Epoch 31/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9444 - top_k_categorical_accuracy: 0.8146     \n",
      "Epoch 32/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9412 - top_k_categorical_accuracy: 0.8110     \n",
      "Epoch 33/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9350 - top_k_categorical_accuracy: 0.8128     \n",
      "Epoch 34/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9315 - top_k_categorical_accuracy: 0.8140     \n",
      "Epoch 35/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9279 - top_k_categorical_accuracy: 0.8092     \n",
      "Epoch 36/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9242 - top_k_categorical_accuracy: 0.8086     \n",
      "Epoch 37/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9211 - top_k_categorical_accuracy: 0.8146     \n",
      "Epoch 38/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9145 - top_k_categorical_accuracy: 0.8158     \n",
      "Epoch 39/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9128 - top_k_categorical_accuracy: 0.8146     \n",
      "Epoch 40/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9090 - top_k_categorical_accuracy: 0.8169     \n",
      "Epoch 41/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9041 - top_k_categorical_accuracy: 0.8181     \n",
      "Epoch 42/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.9025 - top_k_categorical_accuracy: 0.8164     \n",
      "Epoch 43/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8949 - top_k_categorical_accuracy: 0.8199     \n",
      "Epoch 44/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8924 - top_k_categorical_accuracy: 0.8140     \n",
      "Epoch 45/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8909 - top_k_categorical_accuracy: 0.8264     \n",
      "Epoch 46/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8862 - top_k_categorical_accuracy: 0.8205     \n",
      "Epoch 47/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8863 - top_k_categorical_accuracy: 0.8193     \n",
      "Epoch 48/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8818 - top_k_categorical_accuracy: 0.8264     \n",
      "Epoch 49/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8783 - top_k_categorical_accuracy: 0.8258     \n",
      "Epoch 50/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8758 - top_k_categorical_accuracy: 0.8223     \n",
      "Epoch 51/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8709 - top_k_categorical_accuracy: 0.8270     \n",
      "Epoch 52/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8691 - top_k_categorical_accuracy: 0.8276     \n",
      "Epoch 53/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8660 - top_k_categorical_accuracy: 0.8282     \n",
      "Epoch 54/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8615 - top_k_categorical_accuracy: 0.8359     \n",
      "Epoch 55/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8580 - top_k_categorical_accuracy: 0.8312     \n",
      "Epoch 56/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8590 - top_k_categorical_accuracy: 0.8258     \n",
      "Epoch 57/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8570 - top_k_categorical_accuracy: 0.8323     \n",
      "Epoch 58/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8499 - top_k_categorical_accuracy: 0.8329     \n",
      "Epoch 59/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8530 - top_k_categorical_accuracy: 0.8312     \n",
      "Epoch 60/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8488 - top_k_categorical_accuracy: 0.8371     \n",
      "Epoch 61/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8432 - top_k_categorical_accuracy: 0.8335     \n",
      "Epoch 62/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8433 - top_k_categorical_accuracy: 0.8318     \n",
      "Epoch 63/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8392 - top_k_categorical_accuracy: 0.8347     \n",
      "Epoch 64/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8393 - top_k_categorical_accuracy: 0.8318     \n",
      "Epoch 65/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8368 - top_k_categorical_accuracy: 0.8341     \n",
      "Epoch 66/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8316 - top_k_categorical_accuracy: 0.8347     \n",
      "Epoch 67/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8320 - top_k_categorical_accuracy: 0.8341     \n",
      "Epoch 68/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8310 - top_k_categorical_accuracy: 0.8323     \n",
      "Epoch 69/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8283 - top_k_categorical_accuracy: 0.8359     \n",
      "Epoch 70/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s - loss: 1.8267 - top_k_categorical_accuracy: 0.8341     \n",
      "Epoch 71/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8265 - top_k_categorical_accuracy: 0.8341     \n",
      "Epoch 72/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8247 - top_k_categorical_accuracy: 0.8365     \n",
      "Epoch 73/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8215 - top_k_categorical_accuracy: 0.8359     \n",
      "Epoch 74/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8188 - top_k_categorical_accuracy: 0.8365     \n",
      "Epoch 75/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8149 - top_k_categorical_accuracy: 0.8412     \n",
      "Epoch 76/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8149 - top_k_categorical_accuracy: 0.8412     \n",
      "Epoch 77/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8138 - top_k_categorical_accuracy: 0.8294     \n",
      "Epoch 78/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8108 - top_k_categorical_accuracy: 0.8412     \n",
      "Epoch 79/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8127 - top_k_categorical_accuracy: 0.8383     \n",
      "Epoch 80/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8062 - top_k_categorical_accuracy: 0.8377     \n",
      "Epoch 81/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8047 - top_k_categorical_accuracy: 0.8377     \n",
      "Epoch 82/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8020 - top_k_categorical_accuracy: 0.8406     \n",
      "Epoch 83/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8010 - top_k_categorical_accuracy: 0.8383     \n",
      "Epoch 84/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.8013 - top_k_categorical_accuracy: 0.8424     \n",
      "Epoch 85/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7992 - top_k_categorical_accuracy: 0.8442     \n",
      "Epoch 86/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7984 - top_k_categorical_accuracy: 0.8418     \n",
      "Epoch 87/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7962 - top_k_categorical_accuracy: 0.8412     \n",
      "Epoch 88/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7981 - top_k_categorical_accuracy: 0.8377     \n",
      "Epoch 89/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7899 - top_k_categorical_accuracy: 0.8418     \n",
      "Epoch 90/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7962 - top_k_categorical_accuracy: 0.8389     \n",
      "Epoch 91/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7898 - top_k_categorical_accuracy: 0.8424     \n",
      "Epoch 92/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7925 - top_k_categorical_accuracy: 0.8377     \n",
      "Epoch 93/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7921 - top_k_categorical_accuracy: 0.8418     \n",
      "Epoch 94/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7888 - top_k_categorical_accuracy: 0.8442     \n",
      "Epoch 95/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7900 - top_k_categorical_accuracy: 0.8395     \n",
      "Epoch 96/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7971 - top_k_categorical_accuracy: 0.8406     \n",
      "Epoch 97/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7850 - top_k_categorical_accuracy: 0.8418     \n",
      "Epoch 98/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7842 - top_k_categorical_accuracy: 0.8436     \n",
      "Epoch 99/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7838 - top_k_categorical_accuracy: 0.8436     \n",
      "Epoch 100/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7831 - top_k_categorical_accuracy: 0.8406     \n",
      "Epoch 101/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7828 - top_k_categorical_accuracy: 0.8424     \n",
      "Epoch 102/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7778 - top_k_categorical_accuracy: 0.8454     \n",
      "Epoch 103/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7795 - top_k_categorical_accuracy: 0.8448     \n",
      "Epoch 104/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7776 - top_k_categorical_accuracy: 0.8436     \n",
      "Epoch 105/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7789 - top_k_categorical_accuracy: 0.8412     \n",
      "Epoch 106/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7814 - top_k_categorical_accuracy: 0.8424     \n",
      "Epoch 107/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7812 - top_k_categorical_accuracy: 0.8412     \n",
      "Epoch 108/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7750 - top_k_categorical_accuracy: 0.8424     \n",
      "Epoch 109/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7789 - top_k_categorical_accuracy: 0.8448     \n",
      "Epoch 110/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7812 - top_k_categorical_accuracy: 0.8412     \n",
      "Epoch 111/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7773 - top_k_categorical_accuracy: 0.8395     \n",
      "Epoch 112/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7763 - top_k_categorical_accuracy: 0.8448     \n",
      "Epoch 113/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7719 - top_k_categorical_accuracy: 0.8406     \n",
      "Epoch 114/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7780 - top_k_categorical_accuracy: 0.8448     \n",
      "Epoch 115/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7752 - top_k_categorical_accuracy: 0.8430     \n",
      "Epoch 116/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7735 - top_k_categorical_accuracy: 0.8454     \n",
      "Epoch 117/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7741 - top_k_categorical_accuracy: 0.8448     \n",
      "Epoch 118/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7722 - top_k_categorical_accuracy: 0.8466     \n",
      "Epoch 119/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7737 - top_k_categorical_accuracy: 0.8454     \n",
      "Epoch 120/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7724 - top_k_categorical_accuracy: 0.8424     \n",
      "Epoch 121/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7724 - top_k_categorical_accuracy: 0.8454     \n",
      "Epoch 122/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7721 - top_k_categorical_accuracy: 0.8448     \n",
      "Epoch 123/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7747 - top_k_categorical_accuracy: 0.8418     \n",
      "Epoch 124/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7718 - top_k_categorical_accuracy: 0.8436     \n",
      "Epoch 125/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7715 - top_k_categorical_accuracy: 0.8448     \n",
      "Epoch 126/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7681 - top_k_categorical_accuracy: 0.8406     \n",
      "Epoch 127/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7738 - top_k_categorical_accuracy: 0.8460     \n",
      "Epoch 128/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7668 - top_k_categorical_accuracy: 0.8454     \n",
      "Epoch 129/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7677 - top_k_categorical_accuracy: 0.8424     \n",
      "Epoch 130/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7740 - top_k_categorical_accuracy: 0.8436     \n",
      "Epoch 131/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7698 - top_k_categorical_accuracy: 0.8424     \n",
      "Epoch 132/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7704 - top_k_categorical_accuracy: 0.8430     \n",
      "Epoch 133/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7749 - top_k_categorical_accuracy: 0.8448     \n",
      "Epoch 134/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7692 - top_k_categorical_accuracy: 0.8466     \n",
      "Epoch 135/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7738 - top_k_categorical_accuracy: 0.8454     \n",
      "Epoch 136/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7723 - top_k_categorical_accuracy: 0.8395     \n",
      "Epoch 137/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7744 - top_k_categorical_accuracy: 0.8400     \n",
      "Epoch 138/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7691 - top_k_categorical_accuracy: 0.8424     \n",
      "Epoch 139/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1688/1688 [==============================] - 0s - loss: 1.7687 - top_k_categorical_accuracy: 0.8466     \n",
      "Epoch 140/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7685 - top_k_categorical_accuracy: 0.8436     \n",
      "Epoch 141/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7683 - top_k_categorical_accuracy: 0.8412     \n",
      "Epoch 142/150\n",
      "1688/1688 [==============================] - ETA: 0s - loss: 1.7803 - top_k_categorical_accuracy: 0.83 - 0s - loss: 1.7736 - top_k_categorical_accuracy: 0.8418     \n",
      "Epoch 143/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7685 - top_k_categorical_accuracy: 0.8406     \n",
      "Epoch 144/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7717 - top_k_categorical_accuracy: 0.8412     \n",
      "Epoch 145/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7690 - top_k_categorical_accuracy: 0.8436     \n",
      "Epoch 146/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7716 - top_k_categorical_accuracy: 0.8472     \n",
      "Epoch 147/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7693 - top_k_categorical_accuracy: 0.8383     \n",
      "Epoch 148/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7713 - top_k_categorical_accuracy: 0.8406     \n",
      "Epoch 149/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7735 - top_k_categorical_accuracy: 0.8460     \n",
      "Epoch 150/150\n",
      "1688/1688 [==============================] - 0s - loss: 1.7688 - top_k_categorical_accuracy: 0.8406     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241acf97f60>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.metrics import top_k_categorical_accuracy\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=[top_k_categorical_accuracy])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/832 [>.............................] - ETA: 3s\n",
      "top_k_categorical_accuracy: 69.95%\n",
      "[  1.02499534e-05   7.35742958e-07   1.24410326e-06   4.36422852e-05\n",
      "   3.39740480e-04   6.71843372e-05   5.60596697e-02   2.65394688e-01\n",
      "   1.43591515e-05   1.09788800e-06   1.43961927e-06   3.98209295e-07\n",
      "   1.69897430e-05   1.22278436e-08   1.59725005e-06   2.15300433e-02\n",
      "   1.47665082e-03   5.66214435e-02   7.72743590e-07   1.77784439e-03\n",
      "   1.53476522e-05   7.17384364e-06   1.41341744e-07   1.56825911e-06\n",
      "   6.48491323e-07   4.05740830e-05   1.51013537e-05   9.54930410e-02\n",
      "   1.58540365e-06   7.33249326e-05   3.40921861e-06   1.14859522e-05\n",
      "   1.09005969e-05   3.11444805e-04   8.57950151e-02   1.59801051e-01\n",
      "   1.67885914e-01   2.65924409e-05   8.31785798e-03   1.07136900e-02\n",
      "   3.30807234e-05   2.47860182e-04   1.99703407e-03   5.09628677e-04\n",
      "   2.76107487e-04   1.47449697e-04   4.42055836e-02   3.85957719e-05\n",
      "   4.09657322e-03   1.65623985e-02]\n",
      "4654\n",
      "7092\n",
      "[1625, 7092, 7051, 4654, 7014]\n",
      "10277\n",
      "10277\n",
      "[10277, 10190, 1205, 1757, 4527]\n",
      "1625\n",
      "7051\n",
      "[1625, 7051, 7092, 3088, 7014]\n",
      "1565\n",
      "3088\n",
      "[7051, 3088, 4654, 7092, 7014]\n",
      "1205\n",
      "478\n",
      "[10277, 6588, 7245, 6767, 1205]\n",
      "9906\n",
      "7092\n",
      "[7092, 7051, 3088, 1625, 9906]\n",
      "1625\n",
      "1625\n",
      "[1625, 7051, 7092, 3088, 7014]\n",
      "3329\n",
      "3329\n",
      "[3481, 1119, 3329, 3087, 9906]\n",
      "3722\n",
      "4527\n",
      "[10277, 3722, 1205, 7245, 405]\n",
      "1205\n",
      "2703\n",
      "[10277, 6588, 7245, 6767, 1205]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# calculate predictions\n",
    "predictions = model.predict(X_test)\n",
    "# round predictions\n",
    "predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(predictions[0])\n",
    "for i in range(10):\n",
    "    print(keep_act[X_test[i].tolist().index(1)])\n",
    "    print(keep_act[Y_test[i].tolist().index(1)])\n",
    "    print([keep_act[i[1]] for i in sorted(zip(predictions[i], range(len(predictions[i]))), reverse=True)[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
